{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyU-YZEbq2bA",
        "outputId": "907a7123-ff54-442e-f512-9191c9a27a2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Backpropagation Gradient for Weights1:\n",
            "[[-0.00443181 -0.00443181]\n",
            " [-0.00443181 -0.00443181]]\n",
            "\n",
            "Backpropagation Gradient for Weights2:\n",
            "[[-0.03717874 -0.03717874]\n",
            " [-0.03717874 -0.03717874]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def forward_pass(input_data, weights1, weights2, bias):\n",
        "    hidden_layer_input = np.dot(input_data, weights1)+bias\n",
        "    hidden_layer_output =  1/(1+np.exp(-1*hidden_layer_input))\n",
        "    output_layer_input = np.dot(hidden_layer_output, weights2)+bias\n",
        "    output_layer_output =  1/(1+np.exp(-1*output_layer_input))\n",
        "    return hidden_layer_output, output_layer_output\n",
        "\n",
        "def backward_pass(input_data, hidden_layer_output, output_layer_output, target, weights2):\n",
        "    output_error = target - output_layer_output\n",
        "    output_delta = output_error *(output_layer_output)*(1-output_layer_output)\n",
        "    hidden_error = np.dot(output_delta, weights2.T)\n",
        "    hidden_delta = hidden_error *(hidden_layer_output)*(1-hidden_layer_output)\n",
        "    return hidden_delta, output_delta\n",
        "\n",
        "def gradient_descent(weights1, weights2, gradient_weights1, gradient_weights2, learning_rate):\n",
        "    weights1 += learning_rate * gradient_weights1\n",
        "    weights2 += learning_rate * gradient_weights2\n",
        "    return weights1, weights2\n",
        "\n",
        "def main():\n",
        "\n",
        "    weights1 = np.array([[0.5, 0.5],[0.5, 0.5]]) #from layer 1 to layer 2\n",
        "    weights2 = np.array([[0.5, 0.5],[0.5, 0.5]]) #from layer 2 to layer3\n",
        "    input_data = np.array([[1, 1]])\n",
        "    target = np.array([[0.5, 0.5]])\n",
        "    bias = np.array([[1, 1]])\n",
        "\n",
        "    hidden_layer_output, output_layer_output = forward_pass(input_data, weights1, weights2, bias) # Forward pass\n",
        "    hidden_delta, output_delta = backward_pass(input_data, hidden_layer_output, output_layer_output, target, weights2) # Backpropagation\n",
        "\n",
        "    print(\"\\nBackpropagation Gradient for Weights1:\")\n",
        "    print(np.dot(input_data.T, hidden_delta))\n",
        "    print(\"\\nBackpropagation Gradient for Weights2:\")\n",
        "    print(np.dot(hidden_layer_output.T, output_delta))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}